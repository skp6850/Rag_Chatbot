```markdown
# ðŸ¤– eBay RAG Chatbot â€“ Amlgo Labs Assignment

A ** RAG chatbot** that answers questions about eBay's User Agreement using **Ollama + LangChain + Chroma**.

Built with:
- `llama3` (7B) or other Ollama models
- `nomic-embed-text` for embeddings
- `Chroma` as vector DB
- `Streamlit` UI with **real-time streaming responses**


---

## ðŸ—ï¸ Architecture Flow

1. **Document Loader** â†’ Extracts text from `AI Training Document.pdf`
2. **Text Splitter** â†’ Chunks into 100â€“300 word segments
3. **Embedding** â†’ `nomic-embed-text` via Ollama
4. **Vector DB** â†’ Chroma (persistent)
5. **Retriever** â†’ Multi-query expansion for better recall
6. **Generator** â†’ `llama3` with streaming
7. **UI** â†’ Streamlit with real-time response + source passages

---

## ðŸš€ How to Run

### 1. Prerequisites

- Install [Ollama](https://ollama.com):  
  ```bash
  ollama run llama3
  ```
  Or: `ollama run zephyr`, `ollama run mistral`

- Install Python 3.10+ and `pip`

### 2. Setup

```bash
git clone https://github.com/yourusername/ebay-rag-chatbot.git
cd ebay-rag-chatbot
pip install -r requirements.txt
```

### 3. Add PDF

Place the provided `AI Training Document.pdf` in the `data/` folder:

```
data/
â””â”€â”€ AI Training Document.pdf
```

### 4. Run Preprocessing

```bash
python preprocess.py
```

This will:
- Load and clean the PDF
- Split into 100â€“300 word chunks
- Generate embeddings
- Save to `vectordb/`

### 5. Launch App

```bash
streamlit run app.py
```

âœ… The app will open in your browser.

---

## ðŸ§ª Sample Queries

| Query | Expected Answer Snippet |
|------|-------------------------|
| Summary of the policies? | 
| Are vehicles covered under eBay Money Back Guarantee? |
| tell me about the returning policies?|

## ðŸ“‚ Project Structure

```
rag-chatbot/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ AI Training Document.pdf
â”œâ”€â”€ chunks/
â”‚   â”œâ”€â”€ all_chunks.txt
â”‚   â””â”€â”€ chunks.json
â”œâ”€â”€ vectordb/                 # Chroma DB
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ FAST_rag_notebook.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”œâ”€â”€ text_splitter.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â””â”€â”€ rag_pipeline.py
â”œâ”€â”€ preprocess.py             # One-time preprocessing
â”œâ”€â”€ app.py                    # Streamlit UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

> Run Fast_rag_notebook.ipynb file. This file is w/o the UI.
---

## ðŸŽ¥ Demo

[![Demo Video](https://img.youtube.com/vi/YOUTUBE_ID/0.jpg)](https://youtu.be/L39cFqPAWLU)



> The video shows:
> - App loading and preprocessing
> - Asking: *"Tell me about ebay's returning Policies?"*
> - Streaming response with source passages
> - Model selector and chunk count in sidebar

---

## ðŸ›  Model & Embedding Choices

| Component | Choice | Justification |
|--------|--------|-------------|
| **LLM** | `llama3.2` | Lightweight, instruction-tuned, good for Q&A |
| **Embedding** | `nomic-embed-text` | Fast, accurate, trained on legal text |
| **Vector DB** | `Chroma` | Persistent, lightweight, easy to use |
| **Retriever** | `MultiQueryRetriever` | Improves recall with query expansion |

---
